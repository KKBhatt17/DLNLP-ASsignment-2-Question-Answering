{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHRg79OjKDVC"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, os, string, typing, gc, json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_EONOKUKKzX"
      },
      "outputs": [],
      "source": [
        "# loading data\n",
        "path1=\"/content/drive/MyDrive/squad/train.json\"\n",
        "path2=\"/content/drive/MyDrive/squad/dev.json\"\n",
        "with open(path1, 'r', encoding='utf-8') as f:\n",
        "        train_data = json.load(f)\n",
        "with open(path2, 'r', encoding='utf-8') as f:\n",
        "        dev_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The SQUAD data is on the drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ri6uigobiShn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7f6461-b7bc-4419-f631-ae89a75e2eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQDP_oI1B1u8"
      },
      "source": [
        "## Function Definitions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OGYpDRBOfNW"
      },
      "outputs": [],
      "source": [
        "# Extracting the data:\n",
        "\n",
        "def get_data(data:dict)->list:\n",
        "    data = data['data']\n",
        "    que_ans_list = []\n",
        "\n",
        "    for paragraphs in data:\n",
        "        for para in paragraphs['paragraphs']:\n",
        "            context = para['context']\n",
        "\n",
        "            for que_ans in para['qas']:\n",
        "                \n",
        "                id = que_ans['id']\n",
        "                question = que_ans['question']\n",
        "                \n",
        "                for ans in que_ans['answers']:\n",
        "                    answer = ans['text']\n",
        "                    ans_start = ans['answer_start']\n",
        "                    ans_end = ans_start + len(answer)\n",
        "                    que_ans_dict = {}\n",
        "                    que_ans_dict['id'] = id\n",
        "                    que_ans_dict['context'] = context\n",
        "                    que_ans_dict['question'] = question\n",
        "                    que_ans_dict['label'] = [ans_start, ans_end]\n",
        "\n",
        "                    que_ans_dict['answer'] = answer\n",
        "                    que_ans_list.append(que_ans_dict)    \n",
        "\n",
        "    return que_ans_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phLm4yS_CGcK"
      },
      "source": [
        "## Parsing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC58T9heKx_2"
      },
      "outputs": [],
      "source": [
        "train_data_list=get_data(train_data)\n",
        "dev_data_list=get_data(dev_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNZ8kySdCYWj"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI4enocVPR6W"
      },
      "outputs": [],
      "source": [
        "indices=[]\n",
        "word1=\"how\"\n",
        "word2=\"why\"\n",
        "for i in range(0,len(train_data_list)):\n",
        "    ans_len=len(train_data_list[i]['answer'].split())\n",
        "    ctxt_len=len(train_data_list[i]['context'].split())\n",
        "    if ans_len>1 or ctxt_len>100 or word1 in train_data_list[i]['question'].lower() or word2 in train_data_list[i]['question'].lower():\n",
        "        indices.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import seaborn as sns\n",
        "# sns.distplot(cl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "uzJsB4Pd9-Po",
        "outputId": "38697a66-d532-4fd6-a45d-e0c4959e9252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6c1e97f910>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkOKwLH9PUMB"
      },
      "outputs": [],
      "source": [
        "for i in range(len(indices)-1,-1,-1):\n",
        "    train_data_list.pop(indices[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57_5qgsGaDdh"
      },
      "outputs": [],
      "source": [
        "for i in range(0,len(train_data_list)):\n",
        "  train_data_list[i]['con_que']=train_data_list[i]['context']+' [SEP] '+train_data_list[i]['question']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(0,len(train_data_list)):\n",
        "#   train_data_list[i]['que_ans']=train_data_list[i]['question']+' SEP '+train_data_list[i]['answer']"
      ],
      "metadata": {
        "id": "kZGihOLH2YpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmgDeP7OM2mu"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(train_data_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snA97o5bv6u2"
      },
      "source": [
        "## New approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-B07bNUv8YC"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "from string import digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-Y_cKamR2Js"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    #sentence = unicode_to_ascii(sentence.lower().strip())\n",
        "    num_digits= str.maketrans('','', digits)\n",
        "    \n",
        "    sentence= sentence.lower()\n",
        "    sentence= re.sub(\" +\", \" \", sentence)\n",
        "    sentence= re.sub(\"'\", '', sentence)\n",
        "    #sentence= sentence.translate(num_digits)\n",
        "    sentence= sentence.strip()\n",
        "    sentence= re.sub(r\"([?.!,Â¿])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.rstrip().strip()\n",
        "    sentence=  'start_ ' + sentence + ' _end'\n",
        "    \n",
        "    return sentence\n",
        "\n",
        "def create_dataset(qa_list, num_examples):\n",
        "  lines=[]\n",
        "  for i in range(0,len(qa_list)):\n",
        "    lines.append(qa_list[i]['con_que']+'\\t'+qa_list[i]['answer'])\n",
        "  print(len(lines))\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "20NqbV7ESTBl",
        "outputId": "d36eb461-ed53-4efd-9178-8a3c6c085d62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'start_ hello arent you 20 .  thats really good _end'"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "preprocess_sentence(\"Hello aren't you 20. that's really good\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CoRiLQbV9mg",
        "outputId": "e3a32a09-4acf-4d6d-a2e1-cc26f1c7c1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10213\n",
            "start_ in 1815 ,  the british government selected saint helena as the place of detention of napoleon bonaparte .  he was taken to the island in october 1815 .  napoleon stayed at the briars pavilion on the grounds of the balcombe familys home until his permanent residence ,  longwood house ,  was completed in december 1815 .  napoleon died there on 5 may 1821 .  [sep] what year did napoleon bonaparte pass away ? _end\n",
            "start_ 1821 _end\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "sample_size=2000\n",
        "source, target = create_dataset(train_data_list,sample_size)\n",
        "print(source[-1])\n",
        "print(target[-1])\n",
        "type(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NT6XmCHYZC4"
      },
      "outputs": [],
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcugvRYWYikZ"
      },
      "outputs": [],
      "source": [
        "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_sentence_tokenizer.fit_on_texts(source)\n",
        "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
        "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10-6rZx4ZRTR",
        "outputId": "57e5ea21-76ec-4e95-be6b-20a9eecd90ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_sentence_tokenizer.fit_on_texts(target)\n",
        "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n",
        "target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )\n",
        "print(len(target_tensor[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f6vrm9xZWbh",
        "outputId": "2e56abb8-c207-4e38-ba5e-d7a06d841e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "143\n"
          ]
        }
      ],
      "source": [
        "max_target_length= max(len(t) for t in  target_tensor)\n",
        "print(max_target_length)\n",
        "max_source_length= max(len(t) for t in  source_tensor)\n",
        "print(max_source_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl8P5M7OZlYp"
      },
      "outputs": [],
      "source": [
        "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8Cxw_4TcpaD",
        "outputId": "dbf41aac-8692-420a-dd38-24b618ecd6cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600 1600 400 400\n"
          ]
        }
      ],
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(source_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPTEdntgcyOK",
        "outputId": "dd76b6ad-70fc-42fe-f3b6-4a23f3aa57d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "type(input_tensor_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOK9IasCdG-y"
      },
      "outputs": [],
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQy1losGdNm7",
        "outputId": "fe534097-b6cb-4c98-9f97-da66c6100d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "10 ----> start_\n",
            "1 ----> the\n",
            "671 ----> royal\n",
            "630 ----> canadian\n",
            "2751 ----> navy\n",
            "11909 ----> (rcn)\n",
            "2 ----> ,\n",
            "8691 ----> headed\n",
            "18 ----> by\n",
            "1 ----> the\n",
            "11910 ----> commander\n",
            "4 ----> of\n",
            "1 ----> the\n",
            "671 ----> royal\n",
            "630 ----> canadian\n",
            "2751 ----> navy\n",
            "2 ----> ,\n",
            "449 ----> includes\n",
            "1835 ----> 33\n",
            "11911 ----> warships\n",
            "6 ----> and\n",
            "5270 ----> submarines\n",
            "1907 ----> deployed\n",
            "5 ----> in\n",
            "94 ----> two\n",
            "11912 ----> fleets:\n",
            "3156 ----> maritime\n",
            "729 ----> forces\n",
            "3018 ----> pacific\n",
            "11913 ----> (marpac)\n",
            "31 ----> at\n",
            "6735 ----> cfb\n",
            "11914 ----> esquimalt\n",
            "19 ----> on\n",
            "1 ----> the\n",
            "127 ----> west\n",
            "1284 ----> coast\n",
            "2 ----> ,\n",
            "6 ----> and\n",
            "3156 ----> maritime\n",
            "729 ----> forces\n",
            "575 ----> atlantic\n",
            "11915 ----> (marlant)\n",
            "31 ----> at\n",
            "68 ----> her\n",
            "8950 ----> majestys\n",
            "630 ----> canadian\n",
            "1225 ----> dockyard\n",
            "5 ----> in\n",
            "6736 ----> halifax\n",
            "19 ----> on\n",
            "1 ----> the\n",
            "270 ----> east\n",
            "1284 ----> coast\n",
            "2 ----> ,\n",
            "16 ----> as\n",
            "124 ----> well\n",
            "16 ----> as\n",
            "46 ----> one\n",
            "11916 ----> formation:\n",
            "1 ----> the\n",
            "1633 ----> naval\n",
            "8911 ----> reserve\n",
            "1487 ----> headquarters\n",
            "11917 ----> (navreshq)\n",
            "31 ----> at\n",
            "6737 ----> quebec\n",
            "36 ----> city\n",
            "2 ----> ,\n",
            "6737 ----> quebec\n",
            "3 ----> .\n",
            "1 ----> the\n",
            "3008 ----> fleet\n",
            "13 ----> is\n",
            "11918 ----> augmented\n",
            "18 ----> by\n",
            "191 ----> various\n",
            "9109 ----> aircraft\n",
            "6 ----> and\n",
            "2249 ----> supply\n",
            "6738 ----> vessels\n",
            "3 ----> .\n",
            "1 ----> the\n",
            "11919 ----> rcn\n",
            "11920 ----> participates\n",
            "5 ----> in\n",
            "1137 ----> nato\n",
            "6599 ----> exercises\n",
            "6 ----> and\n",
            "900 ----> operations\n",
            "2 ----> ,\n",
            "6 ----> and\n",
            "3677 ----> ships\n",
            "23 ----> are\n",
            "1907 ----> deployed\n",
            "51 ----> all\n",
            "78 ----> over\n",
            "1 ----> the\n",
            "88 ----> world\n",
            "5 ----> in\n",
            "451 ----> support\n",
            "4 ----> of\n",
            "11921 ----> multinational\n",
            "11922 ----> deployments\n",
            "3 ----> .\n",
            "11 ----> [sep]\n",
            "87 ----> where\n",
            "23 ----> are\n",
            "1 ----> the\n",
            "3156 ----> maritime\n",
            "729 ----> forces\n",
            "575 ----> atlantic\n",
            "187 ----> located\n",
            "9 ----> ?\n",
            "12 ----> _end\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> start_\n",
            "935 ----> halifax\n",
            "2 ----> _end\n"
          ]
        }
      ],
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(source_sentence_tokenizer, source_train_tensor[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert( target_sentence_tokenizer, target_train_tensor[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNH6_YIKdS6K",
        "outputId": "86953cf9-5e19-4eb7-b00a-bef3c01c554f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "BUFFER_SIZE = len(source_train_tensor)\n",
        "BATCH_SIZE = 32\n",
        "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(source_sentence_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(target_sentence_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm5mDRQPdiw6",
        "outputId": "230400a4-b3f3-4759-e514-930185ddbd0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 143]), TensorShape([32, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeusqbIxdn1q"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWQg_As8dtKS",
        "outputId": "185558bb-a92c-42e8-dba9-ec05ade1d4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (32, 143, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (32, 1024)\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NronxWxTdxL6"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4ayM5ReAQK",
        "outputId": "1e6f200a-4a70-4761-f3ef-0b4921dc7e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (32, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (32, 143, 1)\n"
          ]
        }
      ],
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIB6C-uqeEz6"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur1Eyu_WeMpi",
        "outputId": "2685aafd-4c59-427e-bffa-e6100fae0ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (32, 1379)\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLAp3qdleP5K"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT58VP6oeUoL"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_-weVdXeYMT"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxP05MY3ecZa",
        "outputId": "003b197a-f12f-4e96-9444-0533ab3a0e0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "steps_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awQScswwefQi",
        "outputId": "24738c35-115a-436b-ea94-2181d3a8c6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 loss 2.485333204269409\n",
            "Epoch 1 Batch 5 loss 2.67923903465271\n",
            "Epoch 1 Batch 10 loss 1.744761347770691\n",
            "Epoch 1 Batch 15 loss 1.6105165481567383\n",
            "Epoch 1 Batch 20 loss 1.5583428144454956\n",
            "Epoch 1 Batch 25 loss 1.4441008567810059\n",
            "Epoch 1 Batch 30 loss 1.2676645517349243\n",
            "Epoch 1 Batch 35 loss 1.3486435413360596\n",
            "Epoch 1 Batch 40 loss 1.2127103805541992\n",
            "Epoch 1 Batch 45 loss 1.2759389877319336\n",
            "Epoch 1 Loss 1.5735\n",
            "Time taken for 1 epoch 465.14484691619873 sec\n",
            "\n",
            "Epoch 2 Batch 0 loss 1.3832800388336182\n",
            "Epoch 2 Batch 5 loss 1.3179389238357544\n",
            "Epoch 2 Batch 10 loss 1.1965248584747314\n",
            "Epoch 2 Batch 15 loss 1.2647531032562256\n",
            "Epoch 2 Batch 20 loss 1.359142541885376\n",
            "Epoch 2 Batch 25 loss 1.3191978931427002\n",
            "Epoch 2 Batch 30 loss 1.1937882900238037\n",
            "Epoch 2 Batch 35 loss 1.1813324689865112\n",
            "Epoch 2 Batch 40 loss 1.1742109060287476\n",
            "Epoch 2 Batch 45 loss 1.1878907680511475\n",
            "Epoch 2 Loss 1.2563\n",
            "Time taken for 1 epoch 434.09901237487793 sec\n",
            "\n",
            "Epoch 3 Batch 0 loss 1.2130502462387085\n",
            "Epoch 3 Batch 5 loss 1.1148886680603027\n",
            "Epoch 3 Batch 10 loss 1.1391932964324951\n",
            "Epoch 3 Batch 15 loss 1.1608930826187134\n",
            "Epoch 3 Batch 20 loss 1.2612097263336182\n",
            "Epoch 3 Batch 25 loss 1.2404441833496094\n",
            "Epoch 3 Batch 30 loss 1.1993225812911987\n",
            "Epoch 3 Batch 35 loss 1.1665053367614746\n",
            "Epoch 3 Batch 40 loss 1.2502409219741821\n",
            "Epoch 3 Batch 45 loss 1.1750389337539673\n",
            "Epoch 3 Loss 1.1991\n",
            "Time taken for 1 epoch 432.3860113620758 sec\n",
            "\n",
            "Epoch 4 Batch 0 loss 1.0726110935211182\n",
            "Epoch 4 Batch 5 loss 1.1174918413162231\n",
            "Epoch 4 Batch 10 loss 1.1216100454330444\n",
            "Epoch 4 Batch 15 loss 1.1634198427200317\n",
            "Epoch 4 Batch 20 loss 1.1793394088745117\n",
            "Epoch 4 Batch 25 loss 1.1857258081436157\n",
            "Epoch 4 Batch 30 loss 1.1354349851608276\n",
            "Epoch 4 Batch 35 loss 1.1305097341537476\n",
            "Epoch 4 Batch 40 loss 1.154306411743164\n",
            "Epoch 4 Batch 45 loss 1.1776511669158936\n",
            "Epoch 4 Loss 1.1611\n",
            "Time taken for 1 epoch 447.1026794910431 sec\n",
            "\n",
            "Epoch 5 Batch 0 loss 1.1358919143676758\n",
            "Epoch 5 Batch 5 loss 1.0901548862457275\n",
            "Epoch 5 Batch 10 loss 1.1275169849395752\n",
            "Epoch 5 Batch 15 loss 1.0403516292572021\n",
            "Epoch 5 Batch 20 loss 1.172616720199585\n",
            "Epoch 5 Batch 25 loss 1.0764509439468384\n",
            "Epoch 5 Batch 30 loss 1.3242859840393066\n",
            "Epoch 5 Batch 35 loss 1.0896010398864746\n",
            "Epoch 5 Batch 40 loss 1.2072982788085938\n",
            "Epoch 5 Batch 45 loss 1.1463384628295898\n",
            "Epoch 5 Loss 1.1329\n",
            "Time taken for 1 epoch 500.81873846054077 sec\n",
            "\n",
            "Epoch 6 Batch 0 loss 1.13379967212677\n",
            "Epoch 6 Batch 5 loss 1.0885515213012695\n",
            "Epoch 6 Batch 10 loss 1.0551116466522217\n",
            "Epoch 6 Batch 15 loss 1.0899361371994019\n",
            "Epoch 6 Batch 20 loss 1.0990859270095825\n",
            "Epoch 6 Batch 25 loss 1.0725653171539307\n",
            "Epoch 6 Batch 30 loss 1.176221251487732\n",
            "Epoch 6 Batch 35 loss 1.128839373588562\n",
            "Epoch 6 Batch 40 loss 1.1107921600341797\n",
            "Epoch 6 Batch 45 loss 1.1486873626708984\n",
            "Epoch 6 Loss 1.1133\n",
            "Time taken for 1 epoch 522.4839556217194 sec\n",
            "\n",
            "Epoch 7 Batch 0 loss 1.0768885612487793\n",
            "Epoch 7 Batch 5 loss 1.077578067779541\n",
            "Epoch 7 Batch 10 loss 1.0239614248275757\n",
            "Epoch 7 Batch 15 loss 1.1379930973052979\n",
            "Epoch 7 Batch 20 loss 1.1622370481491089\n",
            "Epoch 7 Batch 25 loss 1.0674678087234497\n",
            "Epoch 7 Batch 30 loss 1.1410778760910034\n",
            "Epoch 7 Batch 35 loss 1.0539116859436035\n",
            "Epoch 7 Batch 40 loss 1.1184606552124023\n",
            "Epoch 7 Batch 45 loss 1.1124753952026367\n",
            "Epoch 7 Loss 1.0959\n",
            "Time taken for 1 epoch 487.0126430988312 sec\n",
            "\n",
            "Epoch 8 Batch 0 loss 1.0562808513641357\n",
            "Epoch 8 Batch 5 loss 1.0417892932891846\n",
            "Epoch 8 Batch 10 loss 1.0558950901031494\n",
            "Epoch 8 Batch 15 loss 1.1288527250289917\n",
            "Epoch 8 Batch 20 loss 1.121323585510254\n",
            "Epoch 8 Batch 25 loss 1.0861554145812988\n",
            "Epoch 8 Batch 30 loss 1.072765588760376\n",
            "Epoch 8 Batch 35 loss 1.14471435546875\n",
            "Epoch 8 Batch 40 loss 1.150757908821106\n",
            "Epoch 8 Batch 45 loss 1.0740127563476562\n",
            "Epoch 8 Loss 1.0761\n",
            "Time taken for 1 epoch 437.6264431476593 sec\n",
            "\n",
            "Epoch 9 Batch 0 loss 1.0107145309448242\n",
            "Epoch 9 Batch 5 loss 1.1227957010269165\n",
            "Epoch 9 Batch 10 loss 1.0542885065078735\n",
            "Epoch 9 Batch 15 loss 0.9148015379905701\n",
            "Epoch 9 Batch 20 loss 0.9960488677024841\n",
            "Epoch 9 Batch 25 loss 1.0477349758148193\n",
            "Epoch 9 Batch 30 loss 1.0290429592132568\n",
            "Epoch 9 Batch 35 loss 1.003433346748352\n",
            "Epoch 9 Batch 40 loss 1.1193491220474243\n",
            "Epoch 9 Batch 45 loss 1.086400032043457\n",
            "Epoch 9 Loss 1.0498\n",
            "Time taken for 1 epoch 508.9754853248596 sec\n",
            "\n",
            "Epoch 10 Batch 0 loss 0.9706277847290039\n",
            "Epoch 10 Batch 5 loss 0.890734076499939\n",
            "Epoch 10 Batch 10 loss 1.0199569463729858\n",
            "Epoch 10 Batch 15 loss 0.9753791689872742\n",
            "Epoch 10 Batch 20 loss 1.0371475219726562\n",
            "Epoch 10 Batch 25 loss 0.9862731695175171\n",
            "Epoch 10 Batch 30 loss 1.0016988515853882\n",
            "Epoch 10 Batch 35 loss 1.0357428789138794\n",
            "Epoch 10 Batch 40 loss 1.100287675857544\n",
            "Epoch 10 Batch 45 loss 1.0063104629516602\n",
            "Epoch 10 Loss 1.0100\n",
            "Time taken for 1 epoch 444.3872606754303 sec\n",
            "\n",
            "Epoch 11 Batch 0 loss 0.883698582649231\n",
            "Epoch 11 Batch 5 loss 0.9283310770988464\n",
            "Epoch 11 Batch 10 loss 0.8904743194580078\n",
            "Epoch 11 Batch 15 loss 0.9381775856018066\n",
            "Epoch 11 Batch 20 loss 1.0153071880340576\n",
            "Epoch 11 Batch 25 loss 1.005543828010559\n",
            "Epoch 11 Batch 30 loss 0.974094033241272\n",
            "Epoch 11 Batch 35 loss 1.0332281589508057\n",
            "Epoch 11 Batch 40 loss 0.9482995867729187\n",
            "Epoch 11 Batch 45 loss 1.0054619312286377\n",
            "Epoch 11 Loss 0.9689\n",
            "Time taken for 1 epoch 442.38889956474304 sec\n",
            "\n",
            "Epoch 12 Batch 0 loss 0.8798789978027344\n",
            "Epoch 12 Batch 5 loss 0.896328330039978\n",
            "Epoch 12 Batch 10 loss 0.9262076616287231\n",
            "Epoch 12 Batch 15 loss 0.8631134033203125\n",
            "Epoch 12 Batch 20 loss 0.9235934019088745\n",
            "Epoch 12 Batch 25 loss 1.0116058588027954\n",
            "Epoch 12 Batch 30 loss 0.9351917505264282\n",
            "Epoch 12 Batch 35 loss 0.966590404510498\n",
            "Epoch 12 Batch 40 loss 0.9840176105499268\n",
            "Epoch 12 Batch 45 loss 0.9767888784408569\n",
            "Epoch 12 Loss 0.9347\n",
            "Time taken for 1 epoch 431.21522402763367 sec\n",
            "\n",
            "Epoch 13 Batch 0 loss 0.809558093547821\n",
            "Epoch 13 Batch 5 loss 0.852754533290863\n",
            "Epoch 13 Batch 10 loss 0.8125718832015991\n",
            "Epoch 13 Batch 15 loss 0.9039618372917175\n",
            "Epoch 13 Batch 20 loss 0.8922349214553833\n",
            "Epoch 13 Batch 25 loss 0.9267934560775757\n",
            "Epoch 13 Batch 30 loss 0.9549504518508911\n",
            "Epoch 13 Batch 35 loss 0.8090986609458923\n",
            "Epoch 13 Batch 40 loss 0.8825509548187256\n",
            "Epoch 13 Batch 45 loss 0.9263982176780701\n",
            "Epoch 13 Loss 0.8882\n",
            "Time taken for 1 epoch 433.3146035671234 sec\n",
            "\n",
            "Epoch 14 Batch 0 loss 0.7837401628494263\n",
            "Epoch 14 Batch 5 loss 0.748163640499115\n",
            "Epoch 14 Batch 10 loss 0.7672381401062012\n",
            "Epoch 14 Batch 15 loss 0.8063046336174011\n",
            "Epoch 14 Batch 20 loss 0.8575384616851807\n",
            "Epoch 14 Batch 25 loss 0.8823744058609009\n",
            "Epoch 14 Batch 30 loss 0.8481459617614746\n",
            "Epoch 14 Batch 35 loss 0.7984201312065125\n",
            "Epoch 14 Batch 40 loss 0.8844552040100098\n",
            "Epoch 14 Batch 45 loss 0.9339967966079712\n",
            "Epoch 14 Loss 0.8255\n",
            "Time taken for 1 epoch 437.0760416984558 sec\n",
            "\n",
            "Epoch 15 Batch 0 loss 0.7092496752738953\n",
            "Epoch 15 Batch 5 loss 0.6838860511779785\n",
            "Epoch 15 Batch 10 loss 0.6891113519668579\n",
            "Epoch 15 Batch 15 loss 0.7355961799621582\n",
            "Epoch 15 Batch 20 loss 0.7748994827270508\n",
            "Epoch 15 Batch 25 loss 0.746649980545044\n",
            "Epoch 15 Batch 30 loss 0.8352178931236267\n",
            "Epoch 15 Batch 35 loss 0.776396632194519\n",
            "Epoch 15 Batch 40 loss 0.830793023109436\n",
            "Epoch 15 Batch 45 loss 0.8550525903701782\n",
            "Epoch 15 Loss 0.7581\n",
            "Time taken for 1 epoch 447.96916222572327 sec\n",
            "\n",
            "Epoch 16 Batch 0 loss 0.6318581104278564\n",
            "Epoch 16 Batch 5 loss 0.6283808946609497\n",
            "Epoch 16 Batch 10 loss 0.6591033935546875\n",
            "Epoch 16 Batch 15 loss 0.5863065719604492\n",
            "Epoch 16 Batch 20 loss 0.6600911617279053\n",
            "Epoch 16 Batch 25 loss 0.6491665840148926\n",
            "Epoch 16 Batch 30 loss 0.7227380275726318\n",
            "Epoch 16 Batch 35 loss 0.6348441243171692\n",
            "Epoch 16 Batch 40 loss 0.8239935636520386\n",
            "Epoch 16 Batch 45 loss 0.7285300493240356\n",
            "Epoch 16 Loss 0.6924\n",
            "Time taken for 1 epoch 442.87990736961365 sec\n",
            "\n",
            "Epoch 17 Batch 0 loss 0.5926387310028076\n",
            "Epoch 17 Batch 5 loss 0.5240635275840759\n"
          ]
        }
      ],
      "source": [
        "# EPOCHS = 20\n",
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    if batch_loss<0.5:\n",
        "      break\n",
        "    total_loss += batch_loss\n",
        "    if batch % 10 == 0:\n",
        "      print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
        "   \n",
        "      \n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  if total_loss / steps_per_epoch <0.5:\n",
        "    break\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc-3zBHfe65U"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  #print(sentence)\n",
        "  #print(source_sentence_tokenizer.word_index)\n",
        "\n",
        "  inputs = [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_source_length,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
        "\n",
        "  for t in range(max_target_length):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvP3P2GNaz7t"
      },
      "outputs": [],
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1pxw9tLa8AV"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "  \n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er1QhJzCbBhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8dd0cf6-c780-46f4-f44f-311788b6d93c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6c1becba50>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swxaZinAbBkS"
      },
      "outputs": [],
      "source": [
        "translate(u'I am going to work.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
        "\n",
        "  # sentence = preprocess_sentence(sentence)\n",
        "  # #print(sentence)\n",
        "  # #print(source_sentence_tokenizer.word_index)\n",
        "\n",
        "  # inputs = [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  # inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                        #  maxlen=max_source_length,\n",
        "                                                        #  padding='post')\n",
        "  # inputs = tf.convert_to_tensor(inputs)\n",
        "  inputs=sentence\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
        "\n",
        "  for t in range(max_target_length):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "metadata": {
        "id": "86iaWvtjHXlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "  \n",
        "  # print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "metadata": {
        "id": "-_bZeavJHw47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "128N5DlOHw7L",
        "outputId": "0a318ccb-6113-4d42-83b7-a6503d539162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6b98033e10>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting answer for a question.\n",
        "\n",
        "translate('The last opus number that Chopin himself used was 65 allocated to the Cello Sonata in G minor He expressed a deathbed wish that all his unpublished manuscripts be destroyed At the request of the composers mother and sisters however his musical executor Julian Fontana selected 23 unpublished piano pieces and grouped them into eight further opus numbers published in 1855 In 1857 17 Polish songs that Chopin wrote at various stages of his life were collected and published as Op 74 though their order within the opus did not reflect the order of composition SEP Who grouped 23 unpublished pieces and published them as Opp in 1855')"
      ],
      "metadata": {
        "id": "D_C4zmoiHw9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in input_tensor_val[100:110]:\n",
        "  x=np.expand_dims(i,0)\n",
        "  print([translate(x)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk4DDsHFHw_v",
        "outputId": "5311c216-9555-4a2d-fd78-ee0291376897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted translation: architect _end \n",
            "[None]\n",
            "Predicted translation: prajÃ±ÄpÄramitÄ _end \n",
            "[None]\n",
            "Predicted translation: endurance _end \n",
            "[None]\n",
            "Predicted translation: europe _end \n",
            "[None]\n",
            "Predicted translation: copper _end \n",
            "[None]\n",
            "Predicted translation: france _end \n",
            "[None]\n",
            "Predicted translation: 2013 _end \n",
            "[None]\n",
            "Predicted translation: extinct . _end \n",
            "[None]\n",
            "Predicted translation: john _end \n",
            "[None]\n",
            "Predicted translation: 65 _end \n",
            "[None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in input_tensor_train[100:110]:\n",
        "  x=np.expand_dims(i,0)\n",
        "  print([translate(x)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN7Xif4iIYGO",
        "outputId": "acab481f-172f-4c11-cfa7-1db04e6a1a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted translation: 1924 _end \n",
            "[None]\n",
            "Predicted translation: eurasia _end \n",
            "[None]\n",
            "Predicted translation: paris _end \n",
            "[None]\n",
            "Predicted translation: 2006 _end \n",
            "[None]\n",
            "Predicted translation: sovdepia _end \n",
            "[None]\n",
            "Predicted translation: copper _end \n",
            "[None]\n",
            "Predicted translation: hunter-gatherers _end \n",
            "[None]\n",
            "Predicted translation: peaceful _end \n",
            "[None]\n",
            "Predicted translation: orthodox _end \n",
            "[None]\n",
            "Predicted translation: sterilizations _end \n",
            "[None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in target[100:110]:\n",
        "  print(i)\n",
        "for i in source[100:110]:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYKVDzYYHxJk",
        "outputId": "9646aeb4-b48f-4439-e8ad-0de80895005c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_ 7 _end\n",
            "start_ 1817 _end\n",
            "start_ ludwika _end\n",
            "start_ szafarnia _end\n",
            "start_ szafarnia _end\n",
            "start_ 1828 _end\n",
            "start_ zoologist _end\n",
            "start_ 1829 _end\n",
            "start_ french _end\n",
            "start_ 1835 _end\n",
            "start_ fryderyk may have had some piano instruction from his mother ,  but his first professional music tutor ,  from 1816 to 1821 ,  was the czech pianist wojciech Å¼ywny .  his elder sister ludwika also took lessons from Å¼ywny ,  and occasionally played duets with her brother .  it quickly became apparent that he was a child prodigy .  by the age of seven fryderyk had begun giving public concerts ,  and in 1817 he composed two polonaises ,  in g minor and b-flat major .  his next work ,  a polonaise in a-flat major of 1821 ,  dedicated to Å¼ywny ,  is his earliest surviving musical manuscript .  [sep] at what age did chopin start playing publicly ? _end\n",
            "start_ fryderyk may have had some piano instruction from his mother ,  but his first professional music tutor ,  from 1816 to 1821 ,  was the czech pianist wojciech Å¼ywny .  his elder sister ludwika also took lessons from Å¼ywny ,  and occasionally played duets with her brother .  it quickly became apparent that he was a child prodigy .  by the age of seven fryderyk had begun giving public concerts ,  and in 1817 he composed two polonaises ,  in g minor and b-flat major .  his next work ,  a polonaise in a-flat major of 1821 ,  dedicated to Å¼ywny ,  is his earliest surviving musical manuscript .  [sep] what year did chopin compose his first work ? _end\n",
            "start_ fryderyk may have had some piano instruction from his mother ,  but his first professional music tutor ,  from 1816 to 1821 ,  was the czech pianist wojciech Å¼ywny .  his elder sister ludwika also took lessons from Å¼ywny ,  and occasionally played duets with her brother .  it quickly became apparent that he was a child prodigy .  by the age of seven fryderyk had begun giving public concerts ,  and in 1817 he composed two polonaises ,  in g minor and b-flat major .  his next work ,  a polonaise in a-flat major of 1821 ,  dedicated to Å¼ywny ,  is his earliest surviving musical manuscript .  [sep] which of chopins sisters would play music with him ? _end\n",
            "start_ during 1824â28 chopin spent his vacations away from warsaw ,  at a number of locales . [n 4] in 1824 and 1825 ,  at szafarnia ,  he was a guest of dominik dziewanowski ,  the father of a schoolmate .  here for the first time he encountered polish rural folk music .  his letters home from szafarnia (to which he gave the title \"the szafarnia courier\") ,  written in a very modern and lively polish ,  amused his family with their spoofing of the warsaw newspapers and demonstrated the youngsters literary gift .  [sep] in which village did frÃ©dÃ©ric first experience rural polish folk music ? _end\n",
            "start_ during 1824â28 chopin spent his vacations away from warsaw ,  at a number of locales . [n 4] in 1824 and 1825 ,  at szafarnia ,  he was a guest of dominik dziewanowski ,  the father of a schoolmate .  here for the first time he encountered polish rural folk music .  his letters home from szafarnia (to which he gave the title \"the szafarnia courier\") ,  written in a very modern and lively polish ,  amused his family with their spoofing of the warsaw newspapers and demonstrated the youngsters literary gift .  [sep] where did chopin spend his vacation in 1824 and 1825 ? _end\n",
            "start_ in september 1828 chopin ,  while still a student ,  visited berlin with a family friend ,  zoologist feliks jarocki ,  enjoying operas directed by gaspare spontini and attending concerts by carl friedrich zelter ,  felix mendelssohn and other celebrities .  on an 1829 return trip to berlin ,  he was a guest of prince antoni radziwiÅÅ ,  governor of the grand duchy of posenâhimself an accomplished composer and aspiring cellist .  for the prince and his pianist daughter wanda ,  he composed his introduction and polonaise brillante in c major for cello and piano ,  op .  3 .  [sep] what year did chopin visit berlin while still a student ? _end\n",
            "start_ in september 1828 chopin ,  while still a student ,  visited berlin with a family friend ,  zoologist feliks jarocki ,  enjoying operas directed by gaspare spontini and attending concerts by carl friedrich zelter ,  felix mendelssohn and other celebrities .  on an 1829 return trip to berlin ,  he was a guest of prince antoni radziwiÅÅ ,  governor of the grand duchy of posenâhimself an accomplished composer and aspiring cellist .  for the prince and his pianist daughter wanda ,  he composed his introduction and polonaise brillante in c major for cello and piano ,  op .  3 .  [sep] what did the person who chopin went with to berlin do for his work ? _end\n",
            "start_ in september 1828 chopin ,  while still a student ,  visited berlin with a family friend ,  zoologist feliks jarocki ,  enjoying operas directed by gaspare spontini and attending concerts by carl friedrich zelter ,  felix mendelssohn and other celebrities .  on an 1829 return trip to berlin ,  he was a guest of prince antoni radziwiÅÅ ,  governor of the grand duchy of posenâhimself an accomplished composer and aspiring cellist .  for the prince and his pianist daughter wanda ,  he composed his introduction and polonaise brillante in c major for cello and piano ,  op .  3 .  [sep] what year did chopin return to berlin ? _end\n",
            "start_ chopin arrived in paris in late september 1831; he would never return to poland ,  thus becoming one of many expatriates of the polish great emigration .  in france he used the french versions of his given names ,  and after receiving french citizenship in 1835 ,  he travelled on a french passport .  however ,  chopin remained close to his fellow poles in exile as friends and confidants and he never felt fully comfortable speaking french .  chopins biographer adam zamoyski writes that he never considered himself to be french ,  despite his fathers french origins ,  and always saw himself as a pole .  [sep] what version of frÃ©dÃ©rics birth name did he begin using after arriving in france ? _end\n",
            "start_ chopin arrived in paris in late september 1831; he would never return to poland ,  thus becoming one of many expatriates of the polish great emigration .  in france he used the french versions of his given names ,  and after receiving french citizenship in 1835 ,  he travelled on a french passport .  however ,  chopin remained close to his fellow poles in exile as friends and confidants and he never felt fully comfortable speaking french .  chopins biographer adam zamoyski writes that he never considered himself to be french ,  despite his fathers french origins ,  and always saw himself as a pole .  [sep] in what year did frÃ©dÃ©ric officially acquire french citizenship ? _end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BTqcNv3TPeS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! cp -r /content/training_checkpoints/checkpoint /content/drive/MyDrive/squad/checkpoints/tenepochthirtytwo"
      ],
      "metadata": {
        "id": "Tiy3c9wRJlZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! cp -r /content/training_checkpoints/ckpt-10.data-00000-of-00001 /content/drive/MyDrive/squad/checkpoints/tenepochthirtytwo"
      ],
      "metadata": {
        "id": "65RSc_qPL9SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! cp -r /content/training_checkpoints/ckpt-10.index /content/drive/MyDrive/squad/checkpoints/tenepochthirtytwo"
      ],
      "metadata": {
        "id": "TLwLZghiMA7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UAHJJokA6o1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "QA_System_on_SQuAD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}